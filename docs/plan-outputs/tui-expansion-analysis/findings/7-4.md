# Task 7.4: Analyze Batch Progress Tracking

## Analysis Overview

This analysis documents how batch completion is tracked, partial batch completion handling, and batch retry behavior.

## Run Tracking System

### Run Lifecycle

```javascript
// scripts/lib/plan-status.js:1116-1135
function startRun(planPath) {
  const status = loadStatus(planPath);
  if (!status) return null;

  const runId = `run-${Date.now()}`;
  const run = {
    runId,
    startedAt: new Date().toISOString(),
    tasksCompleted: 0,
    tasksFailed: 0
  };

  status.runs = status.runs || [];
  status.runs.push(run);

  if (saveStatus(planPath, status)) {
    return runId;
  }
  return null;
}
```

### Run Completion

```javascript
// scripts/lib/plan-status.js:1145-1157
function completeRun(planPath, runId, completed, failed) {
  const status = loadStatus(planPath);
  if (!status || !status.runs) return false;

  const run = status.runs.find(r => r.runId === runId);
  if (!run) return false;

  run.completedAt = new Date().toISOString();
  run.tasksCompleted = completed;
  run.tasksFailed = failed;

  return saveStatus(planPath, status);
}
```

### Run Data Structure

```typescript
interface Run {
  runId: string;              // Format: "run-{timestamp}"
  startedAt: string;          // ISO 8601 timestamp
  completedAt?: string;       // Set on completion
  tasksCompleted: number;     // Final count
  tasksFailed: number;        // Final count
}
```

## Task-Level Status Tracking

### Status Transitions

```
pending → in_progress → completed
              ↓
           failed (→ pending on retry)
              ↓
           skipped
```

### Task Status Fields

```typescript
interface TaskStatus {
  id: string;
  status: 'pending' | 'in_progress' | 'completed' | 'failed' | 'skipped';
  startedAt?: string;         // When task began
  completedAt?: string;       // When task finished
  error?: string;             // Error message if failed
  retryCount?: number;        // Number of retry attempts
  lastRetryError?: string;    // Most recent error
}
```

## Partial Batch Completion

### Orchestrator Handling

The orchestrator handles partial completion gracefully:

```python
# scripts/plan_orchestrator.py:841-851
# Check completion
if status.is_complete:
    if self.use_tui:
        self.tui.set_status("Plan complete!")
        time.sleep(2)
    else:
        self.print_completion(status, "complete")
    self._cleanup()
    return 0
```

### Per-Task Granular Status

Implement.md instructs granular status updates:

```markdown
### 5. Implement Each Task

For each selected task:

1. **Mark task as started:**
   - Call `markTaskStarted(planPath, taskId)` to update status to `in_progress`
   - This updates the status.json file with current timestamp

...

7. **Mark complete or failed** after verification (see Section 6)
```

### Partial Batch Behavior

| Scenario | Behavior |
|----------|----------|
| 3/5 tasks complete before timeout | 3 marked completed, 2 remain in_progress |
| 1 task fails in batch | Failed task marked, others continue |
| Claude session crashes | in_progress tasks detected as stuck (30 min) |
| Graceful shutdown | Current batch may complete partially |

## Stuck Task Detection

### Detection Algorithm

```python
# scripts/plan_orchestrator.py:421-438
def detect_stuck_tasks(self) -> list:
    """Detect and mark stuck tasks as failed."""
    try:
        result = subprocess.run(
            ["node", "scripts/status-cli.js", "detect-stuck"],
            capture_output=True,
            text=True,
            timeout=30,
            cwd=self.working_dir,
        )
        if result.returncode != 0:
            return []

        data = json.loads(result.stdout)
        return data.get("stuckTasks", [])
    except Exception as e:
        self.logger.warning(f"Failed to detect stuck tasks: {e}")
        return []
```

### Stuck Detection in Main Loop

```python
# scripts/plan_orchestrator.py:854-861
# Check for stuck tasks and mark them as failed
stuck_tasks = self.detect_stuck_tasks()
if stuck_tasks:
    if self.use_tui:
        self.tui.set_status(f"Detected {len(stuck_tasks)} stuck task(s)")
    for task in stuck_tasks:
        self.logger.info(
            f"  Stuck: {task.get('id')} (in_progress for {task.get('elapsedMinutes', '?')} min)"
        )
```

### Stuck Task Threshold

- **Default**: 30 minutes in `in_progress` status
- **Detection**: Runs before each iteration
- **Action**: Tasks marked as failed with error "stuck"

## Batch Retry Behavior

### Retry Count Management

```python
# scripts/plan_orchestrator.py:388-404
def increment_retry(self, task_id: str, error: str) -> dict:
    """Increment retry count for a failed task."""
    try:
        result = subprocess.run(
            ["node", "scripts/status-cli.js", "increment-retry", task_id, "--error", error],
            capture_output=True,
            text=True,
            timeout=30,
            cwd=self.working_dir,
        )
        if result.returncode != 0:
            return {"canRetry": False, "error": result.stderr}

        return json.loads(result.stdout)
    except Exception as e:
        self.logger.warning(f"Failed to increment retry for {task_id}: {e}")
        return {"canRetry": False, "error": str(e)}
```

### Getting Retryable Tasks

```python
# scripts/plan_orchestrator.py:369-386
def get_retryable_tasks(self) -> list:
    """Get failed tasks that can be retried (retryCount < 2)."""
    try:
        result = subprocess.run(
            ["node", "scripts/status-cli.js", "retryable"],
            capture_output=True,
            text=True,
            timeout=30,
            cwd=self.working_dir,
        )
        if result.returncode != 0:
            return []

        data = json.loads(result.stdout)
        return data.get("tasks", [])
    except Exception as e:
        self.logger.warning(f"Failed to get retryable tasks: {e}")
        return []
```

### Retry Logic in Main Loop

```python
# scripts/plan_orchestrator.py:864-897
# Check if blocked - but first try to retry failed tasks
if status.is_blocked:
    # Try to find retryable tasks
    retryable = self.get_retryable_tasks()
    if retryable:
        if self.use_tui:
            self.tui.set_status(f"Retrying {len(retryable)} failed task(s)")

        # Reset the first retryable task and continue
        for task in retryable[:self.batch_size]:
            task_id = task.get('id')
            retry_count = task.get('retryCount', 0) + 1
            if self.use_tui:
                self.tui.set_status(f"Retry #{retry_count} for task {task_id}")
            self.reset_task_for_retry(task_id)
        # Refresh status and continue loop
        continue
    else:
        # No retryable tasks left, truly blocked
        self.tui.set_status("Plan blocked - all retries exhausted")
        return 2
```

### Retry Limits

- **Max Retries**: 2 attempts per task
- **Blocking**: Plan blocked if no retryable tasks and pending=0

## TUI Progress Display

### Current Implementation

```python
# scripts/lib/tui.py:246-292
def _render_progress(self) -> Panel:
    """Render the progress bar panel."""
    # Calculate percentage from actual counts
    if self.total_tasks > 0:
        self.percentage = int((self.completed_tasks / self.total_tasks) * 100)

    bar_width = 50
    filled = int(bar_width * self.percentage / 100)
    bar = "█" * filled + "░" * (bar_width - filled)

    progress_text = Text()
    progress_text.append(f"[{bar}] {self.percentage}%", style="bold green")

    # Add heartbeat indicator for Claude activity
    if self.claude_running:
        spinner = self._heartbeat_chars[self._heartbeat_index]
        progress_text.append(f"  {spinner} Claude working", style="cyan")

    # Task counts
    progress_text.append(f"\n{self.completed_tasks}/{self.total_tasks} tasks")
    if self.in_progress_count > 0:
        progress_text.append(f"  |  Working: {self.in_progress_count}", style="cyan")
    if self.failed_tasks > 0:
        progress_text.append(f"  |  Failed: {self.failed_tasks}", style="red")
```

### Status Updates from status.json

```python
# scripts/plan_orchestrator.py:558-580
def _on_status_update(self, status_data: Dict):
    """Callback when status.json is updated (TUI mode)."""
    if self.tui:
        summary = status_data.get('summary', {})
        self.tui.set_progress(
            summary.get('completed', 0),
            summary.get('totalTasks', 0),
            summary.get('pending', 0),
            summary.get('failed', 0),
            summary.get('in_progress', 0)
        )

        # Update current phase
        current_phase = status_data.get('currentPhase', '')
        if current_phase:
            self.tui.set_phase(current_phase)

        # Update task lists
        tasks = status_data.get('tasks', [])
        in_progress = [t for t in tasks if t.get('status') == 'in_progress']
        completed = [t for t in tasks if t.get('status') == 'completed'][-5:]
        self.tui.update_tasks(in_progress, list(reversed(completed)))
```

## TUI Visualization Opportunities

### Batch Progress Panel

```
Current Batch:
├── [===     ] 3.1 Merge ORCHESTRATOR.md (45%)
├── [========] 3.2 Merge ARCHITECTURE.md ✓
├── [==      ] 3.3 Create redirect file (25%)
└── [        ] 3.4 Remove duplicate (waiting)

Batch Progress: 2/4 tasks | 43% of batch
```

### Run History Panel

```
Recent Runs:
├── run-1735123456 [12:34:56] 5 completed, 0 failed (2m 34s)
├── run-1735123100 [12:28:20] 3 completed, 1 failed (3m 12s)
└── run-1735122800 [12:23:20] 5 completed, 0 failed (1m 45s)

Total: 47 runs | 234 tasks completed | 5 failures
```

### Retry Status Panel

```
Retry Status:
├── 3.1 - Retry #2 of 2 (in progress)
│   └── Last error: Type mismatch in generated code
├── 4.2 - Retries exhausted (blocked)
│   └── Error: Missing dependency file
└── 5.1 - No retries needed
```

### Stuck Task Warning

```
⚠ Stuck Task Detected:
├── Task 3.1 in_progress for 32 minutes
├── Last activity: 12:02:34
└── Action: [Mark Failed] [Continue Waiting] [Skip]
```

## Key Findings

1. **Run-Based Tracking**: Each orchestrator iteration creates a run record with start/complete timestamps and task counts

2. **Granular Task Status**: Individual tasks tracked with status, timestamps, errors, and retry counts

3. **Partial Completion Supported**: Tasks complete independently; batch failures don't lose completed work

4. **Automatic Stuck Detection**: 30-minute threshold for in_progress tasks, marked as failed

5. **Retry System**: Up to 2 retries per task before declaring blocked

6. **TUI Receives Updates**: Status monitor polls status.json at 500ms intervals for real-time display

7. **Missing Batch-Level Metrics**: No explicit batch tracking (only run tracking); batch progress inferred from in_progress tasks

## Proposed Enhancements

### Batch Tracking Data Structure

```typescript
interface Batch {
  batchId: string;
  runId: string;           // Parent run
  startedAt: string;
  completedAt?: string;
  taskIds: string[];       // Tasks in this batch
  completedTasks: number;
  failedTasks: number;
}
```

### Batch Events for TUI

```javascript
// Proposed events
{ type: 'batch:started', batchId: 'b-123', taskIds: ['3.1', '3.2', '3.3'] }
{ type: 'batch:task:completed', batchId: 'b-123', taskId: '3.1' }
{ type: 'batch:completed', batchId: 'b-123', completed: 3, failed: 0 }
```

## Files Analyzed

- `scripts/lib/plan-status.js:1116-1157` - Run tracking functions
- `scripts/plan_orchestrator.py:369-438` - Retry and stuck detection
- `scripts/plan_orchestrator.py:854-897` - Main loop retry handling
- `scripts/lib/tui.py:246-292` - Progress rendering
- `.claude/commands/plan/implement.md:545-688` - Task status management

# Task 7.3: Analyze Parallel Agent Spawning

## Analysis Overview

This analysis documents when and how agents are spawned in parallel vs sequentially, including agent spawn limits and resource considerations.

## Agent Execution Strategy

### Source: implement.md Section 5.1-5.4

The agent execution strategy is defined in `.claude/commands/plan/implement.md`:

```markdown
### 5.1. Agent Execution Strategy

Even a single task may require multiple agents working in parallel.
Analyze each task to determine the optimal execution approach.

| Scenario | Agent Strategy |
|----------|----------------|
| Single file creation | 1 agent |
| Multiple independent files | Parallel agents (1 per file or file group) |
| Test file + implementation | Parallel agents (test agent + impl agent) |
| Refactoring across files | Parallel agents grouped by module |
| Analysis + code generation | Sequential (analysis first, then code agents) |
```

## When Agents Run in Parallel

### Parallel Execution Criteria

```markdown
### 5.3. Sequential vs Parallel Decision

**Run agents in parallel when:**
- Files are independent (no imports between them)
- Work can be divided by module/feature
- Tests and implementation don't share setup code
```

### Resource Limits

```markdown
### 5.2. Parallel Agent Execution Rules

**Resource awareness:**
- Maximum 5 parallel agents per task
- Balance load across agents (don't overload one agent with many files)
- Group related files to the same agent when they have interdependencies
```

## When Agents Run Sequentially

### Sequential Execution Criteria

```markdown
**Run agents sequentially when:**
- Later work depends on earlier output (e.g., generate types first, then use them)
- Files have circular dependencies that need coordinated changes
- A shared foundation must be established first

**Example sequential flow:**
```
Step 1: Agent generates shared types (src/types/auth.ts)
        ↓ (wait for completion)
Step 2: Parallel agents use those types:
        - Agent A: auth middleware
        - Agent B: auth utilities
        - Agent C: auth tests
```

## Read-Only Agent Pattern

### Pattern Description

```markdown
### 5.2. Parallel Agent Execution Rules

**IMPORTANT - Read-Only Agent Pattern:**
Agents should RETURN content, not write files directly. This avoids
permission issues and provides a checkpoint before changes are committed.

When launching agents, include this in the prompt:
```
IMPORTANT: Do NOT write files directly. Instead:
1. Analyze the task requirements
2. Generate the complete code/content
3. Return your output in this format:
   FILE: <path>
   ```<language>
   <content>
   ```
4. The main conversation will handle file writing
```

### Execution Rules

```markdown
**Parallel execution rules:**
1. Launch all independent agents simultaneously using multiple Task tool calls
2. Wait for all agents to complete before proceeding
3. If one agent fails, continue others but note the failure
4. Collect all results (generated content) before writing any files
5. **Main conversation writes files** after collecting all agent outputs
6. Verify files were written correctly before marking task complete
```

## Orchestrator-Level Agent Tracking

### TUI Activity Tracker

```python
# scripts/lib/tui.py:50-66
class ActivityTracker:
    """Tracks all tool calls and activities during orchestration."""

    def __init__(self, max_history: int = 100):
        self.activities: deque = deque(maxlen=max_history)
        self.active_tools: Dict[str, Activity] = {}
        self.stats = {
            'reads': 0,
            'edits': 0,
            'writes': 0,
            'bash_commands': 0,
            'agents_spawned': 0,  # Task agent counter
            'greps': 0,
            'globs': 0,
            'total_tools': 0
        }
```

### Agent Spawn Detection

```python
# scripts/lib/tui.py:113-115
elif tool_name == 'Task':
    desc = details.get('description', 'agent')
    return f"Task: {desc}"
```

## Orchestrator Batch Prompt

### Prompt Building with Constraints

```python
# scripts/plan_orchestrator.py:974-1015
def _build_prompt(self, status: PlanStatus, next_tasks: list) -> str:
    """Build the prompt for Claude Code.

    Uses command invocation with --autonomous flag instead of inline instructions.
    The /plan:implement command handles:
    - Task status tracking (mark-started, mark-complete, mark-failed)
    - Template variable handling
    - Agent execution strategy (parallel agents, read-only pattern)
    - Run tracking (startRun/completeRun)
    - Findings collection
    - Sophisticated error handling
    """
    task_ids = " ".join(t.get('id', '') for t in next_tasks)
    task_list = "\n".join(
        f"  - {t.get('id')}: {t.get('description')}"
        for t in next_tasks
    )

    constraints_section = self._build_constraints_section(next_tasks)

    prompt = f"""Execute these tasks from the plan:

{task_list}

Plan: {status.plan_path}
Progress: {status.percentage}% ({status.completed}/{status.total} tasks)

Run: /plan:implement {task_ids} --autonomous
{constraints_section}
## Rules

- Execute autonomously - do NOT ask for confirmation
- Check for [SEQUENTIAL] annotations in the plan - run marked tasks one at a time
- Detect file conflicts - if multiple tasks modify the same file, run sequentially
- Stop after completing this batch or if blocked by unrecoverable error
- If a task fails, the command will mark it failed and continue to next task
- Check progress: `node scripts/status-cli.js progress`"""
    return prompt
```

## Decision Matrix: Parallel vs Sequential

### Task-Level Decisions

| Task Type | Agent Strategy | Rationale |
|-----------|----------------|-----------|
| Create single file | 1 agent | No parallelism benefit |
| Create multiple independent files | N parallel agents | Maximum throughput |
| Create types + implementations | Sequential → Parallel | Types must exist first |
| Refactor related files | Parallel by module | Minimize conflicts |
| Analysis + implementation | Sequential | Analysis informs code |
| Test + implementation (independent) | 2 parallel agents | No shared setup |
| Test + implementation (shared fixtures) | Sequential or 1 agent | Fixtures needed first |

### Batch-Level Decisions (Orchestrator)

| Batch Configuration | Execution Strategy |
|--------------------|-------------------|
| Multiple tasks, same phase | Parallel-eligible |
| Multiple tasks, different phases | Follow phase order |
| Tasks with [SEQUENTIAL] annotation | One at a time |
| Tasks with file conflicts | Sequential execution |

## TUI Visualization Opportunities

### Agent Activity Panel Enhancements

Current capabilities in `tui.py`:
- Agent spawn counter (`agents_spawned`)
- Active agent list display
- Completion tracking with duration

### Proposed Enhancements

1. **Parallel Agent Visualization**
   ```
   Agents (3 active):
   ├── [Agent 1] auth middleware → [===    ] 45%
   ├── [Agent 2] auth utilities → [=====  ] 70%
   └── [Agent 3] auth tests     → [==     ] 30%
   ```

2. **Agent Dependency Graph**
   ```
   Agent Execution:
   [1] types.ts ─┬─> [2] middleware.ts (waiting)
                 ├─> [3] utils.ts (waiting)
                 └─> [4] tests.ts (waiting)
   ```

3. **Resource Usage Indicators**
   ```
   Resources: [███░░] 3/5 agents | CPU: 45% | Memory: 2.1GB
   ```

4. **Agent Failure Handling**
   ```
   ⚠ Agent 2 failed: Syntax error in generated code
     → Other agents continuing...
     → Collecting partial results
   ```

### Agent Stats Panel

```
Agent Statistics:
├── Total Spawned: 47
├── Parallel Batches: 12
├── Average Batch Size: 2.8
├── Sequential Fallbacks: 5
└── Failures: 2 (4.3%)
```

## Key Findings

1. **Two-Level Parallelism**:
   - Task level: Multiple tasks in a batch
   - Agent level: Multiple agents per task

2. **Read-Only Pattern Critical**: Agents return content, main conversation writes - prevents file conflicts

3. **5-Agent Limit**: Maximum parallel agents per task for resource management

4. **Sequential Fallback**: Agents go sequential when dependencies exist between generated files

5. **TUI Tracks Agent Stats**: Current TUI counts agent spawns but doesn't visualize parallel execution

6. **Constraint Propagation**: [SEQUENTIAL] annotations propagate from plan → status-cli → orchestrator → implement command

## Architectural Considerations

### Current Limitations
- No real-time agent progress tracking (only start/complete)
- No visibility into agent-internal parallelism from TUI
- Agent spawn stats are aggregate, not per-batch

### Potential Improvements
- Event streaming for agent progress
- Agent batch visualization
- Resource utilization monitoring
- Agent failure recovery UI

## Files Analyzed

- `.claude/commands/plan/implement.md:545-659` - Agent execution strategy
- `scripts/lib/tui.py:50-164` - Activity tracking
- `scripts/plan_orchestrator.py:974-1043` - Prompt building

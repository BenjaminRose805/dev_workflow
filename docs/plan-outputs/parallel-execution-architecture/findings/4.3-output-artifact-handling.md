# Task 4.3: Task Output/Artifact Handling for Parallel Execution

**Status:** completed
**Date:** 2025-12-25

## Summary

Analyzed how task outputs and artifacts are managed in the plan execution system, focusing on parallel execution safety. The system employs several mechanisms to support parallel execution: atomic file writes, file locking with proper-lockfile, task-isolated findings storage, and a read-only agent pattern. While well-designed for moderate parallelism, there are potential race conditions at high concurrency levels.

## Output Storage Architecture

### 1. Status Tracking (status.json)

**Location:** `docs/plan-outputs/{plan-name}/status.json`

**File Path:** `/home/benjamin/tools/dev_workflow/scripts/lib/plan-status.js`

The status.json file is the authoritative source of truth for task execution state. Key characteristics:

| Aspect | Implementation | Parallel Safety |
|--------|---------------|-----------------|
| Storage | Single JSON file per plan | Contention point |
| Write method | Atomic write (temp + rename) | Crash-safe |
| Locking | proper-lockfile with retries | Race condition protected |
| Backup | Auto-backup before writes | Recovery possible |

**Status.json Structure:**
```json
{
  "_comment": "Source of truth for execution state",
  "planPath": "docs/plans/my-plan.md",
  "planName": "Plan Title",
  "tasks": [
    {
      "id": "1.1",
      "status": "completed",
      "startedAt": "...",
      "completedAt": "...",
      "duration": 4806,
      "findingsPath": "docs/plan-outputs/.../findings/1-1.md"
    }
  ],
  "summary": {
    "totalTasks": 29,
    "completed": 15,
    "pending": 9,
    "in_progress": 5,
    "failed": 0,
    "skipped": 0
  },
  "runs": [...]
}
```

### 2. Findings Storage

**Location:** `docs/plan-outputs/{plan-name}/findings/{task-id}.md`

**File Path:** `/home/benjamin/tools/dev_workflow/docs/plan-outputs/FINDINGS-FORMAT.md`

Each task has its own dedicated findings file:
- **Naming:** Task ID with dots replaced by hyphens (e.g., `1.1` → `1-1.md`)
- **Isolation:** Each task writes to a unique file
- **Parallel Safety:** HIGH - No shared state between task findings

### 3. Timestamps Storage

**Location:** `docs/plan-outputs/{plan-name}/timestamps/`

**File Path:** `/home/benjamin/tools/dev_workflow/docs/plan-outputs/TIMESTAMPS-FORMAT.md`

Detailed timing data with multiple files:
```
timestamps/
├── runs/run-{timestamp}.json    # Per-run timing
├── tasks/{task-id}.json         # Per-task history
└── summary.json                 # Aggregated statistics
```

## Parallel Execution Safety Mechanisms

### 1. Atomic File Writes

**File Path:** `/home/benjamin/tools/dev_workflow/scripts/lib/file-utils.js`

```javascript
function writeFileAtomic(filePath, content) {
  const tempPath = path.join(dir, `.${basename}.${process.pid}.${Date.now()}.tmp`);
  // Write to temp file
  fs.writeFileSync(tempPath, content, 'utf-8');
  // Rename atomically (atomic on POSIX systems)
  fs.renameSync(tempPath, filePath);
}
```

**Key Features:**
- Uses process ID + timestamp for unique temp file names
- Prevents partial writes from corrupting files
- Atomic on POSIX systems (rename is atomic)

### 2. File Locking with proper-lockfile

**File Path:** `/home/benjamin/tools/dev_workflow/scripts/lib/plan-output-utils.js`

```javascript
const LOCK_OPTIONS = {
  stale: 60000,        // Lock stale after 60 seconds
  retries: {
    retries: 10,       // Up to 10 retries
    factor: 1.5,       // Exponential backoff
    minTimeout: 100,   // Start at 100ms
    maxTimeout: 2000,  // Max 2 seconds between retries
    randomize: true    // Jitter to prevent thundering herd
  }
};
```

**Lock Acquisition Pattern:**
```javascript
async function acquireLock(statusPath, timeoutMs = LOCK_TIMEOUT_MS) {
  const release = await Promise.race([
    lockfile.lock(statusPath, LOCK_OPTIONS),
    timeoutPromise
  ]);
  return release;
}
```

### 3. Summary Recalculation Safety

The system includes a "safety net" that recalculates summary counts after each update:

```javascript
// Safety net: recalculate if summary seems off
const calculated = recalculateSummary(status);
let drift = false;
for (const key of Object.keys(calculated)) {
  if (status.summary[key] !== calculated[key]) {
    drift = true;
    break;
  }
}
if (drift) {
  status.summary = calculated;
}
```

This catches any drift from bugs or concurrent modifications.

### 4. Batch Update Transaction

**File Path:** `/home/benjamin/tools/dev_workflow/scripts/lib/plan-output-utils.js`

For multiple task updates, a batch operation ensures atomicity:

```javascript
async function batchUpdateTasks(planPath, updates) {
  const lockResult = await loadStatusWithLock(planPath);
  // ... process all updates ...
  // Single atomic write for all updates
  const saveSuccess = saveStatus(planPath, status);
}
```

## Potential Race Conditions

### 1. Status.json Contention

**Scenario:** Multiple parallel tasks completing simultaneously

**Risk Level:** MEDIUM

**Analysis:**
- Lock acquisition with 10 retries and exponential backoff (up to ~10s total)
- Timeout after 10 seconds - could fail if many tasks compete
- Lock stale threshold of 60 seconds handles stuck processes

**Current Mitigation:**
- Atomic writes prevent corruption
- Lock retries with randomized jitter prevent thundering herd
- Summary recalculation on each update catches drift

**Remaining Gap:**
- High concurrency (>5 parallel agents) could still cause timeout
- No queuing mechanism for pending updates

### 2. Summary Count Drift

**Scenario:** Two tasks updating summary counts simultaneously

**Risk Level:** LOW (mitigated)

```
Task A: Read (pending=5) → Decrement → Write (pending=4)
Task B: Read (pending=5) → Decrement → Write (pending=4)
Result: Should be pending=3, but could be pending=4
```

**Mitigation:**
- File locking prevents simultaneous reads
- Safety net recalculation catches any drift
- Auto-fix on load validates against actual task counts

### 3. Findings File Collision

**Scenario:** Same task ID written twice (rare - should be impossible)

**Risk Level:** VERY LOW

Each task writes to a unique file path. Would only collide if:
- Same task executed twice simultaneously (logic error)
- Task ID collision in plan (parsing error)

### 4. Git Working Directory Conflicts

**Scenario:** Multiple tasks committing changes

**Risk Level:** HIGH for parallel plans, LOW for parallel tasks

**Current State:**
- Tasks in same phase can run in parallel
- Each task commits after completion
- No git-level coordination between parallel commits

**Potential Issue:**
- Fast-forward pushes could fail if another task pushed first
- Merge conflicts possible if tasks modify same files

## Current Coordination Mechanisms

### 1. Read-Only Agent Pattern

**File Path:** `/home/benjamin/tools/dev_workflow/.claude/commands/plan/implement.md`

Agents generate content but don't write files directly:

```
IMPORTANT: Do NOT write files directly. Instead:
1. Analyze the task requirements
2. Generate the complete code/content
3. Return your output in this format:
   FILE: <path>
   ```<language>
   <content>
   ```
4. The main conversation will handle file writing
```

**Benefits for Parallelism:**
- Prevents race conditions from concurrent agent writes
- Provides checkpoint before changes are committed
- Main conversation can detect conflicts before writing

### 2. [SEQUENTIAL] Constraint Enforcement

**File Path:** `/home/benjamin/tools/dev_workflow/scripts/lib/plan-status.js`

```javascript
function parseExecutionNotes(planContent) {
  // Match: **Execution Note:** Tasks X.Y-X.Z are [SEQUENTIAL] - reason
  const notePattern = /\*\*Execution Note:\*\*\s*Tasks?\s+([\d.,\s-]+)\s+(?:are|is)\s+\[SEQUENTIAL\]/gi;
  // ... parse and expand task ranges ...
}
```

Tasks marked `[SEQUENTIAL]` are:
- Parsed at plan initialization
- Stored in task.executionConstraints
- Enforced by orchestrator/batch commands

### 3. Recovery Mechanisms

**Backup Before Write:**
```javascript
function createBackup(statusPath) {
  const backupPath = getBackupPath(statusPath); // .bak extension
  fs.copyFileSync(statusPath, backupPath);
}
```

**Rebuild from Markdown (last resort):**
```javascript
function rebuildStatusFromMarkdown(planPath) {
  // Parse plan markdown and recreate status.json
  // All tasks reset to pending (completion state lost)
}
```

## Concurrency Limits

### Current Limits

| Resource | Limit | Enforcement |
|----------|-------|-------------|
| Parallel agents per task | 5 | Documented guideline |
| Lock acquisition timeout | 10 seconds | Code enforced |
| Lock stale threshold | 60 seconds | Auto-release |
| Retry attempts | 10 | With exponential backoff |

### Recommendations for Higher Parallelism

1. **Batch status updates** - Already implemented, use `batchUpdateTasks()` for groups
2. **Increase lock timeout** - For >5 parallel tasks, consider 20-30s timeout
3. **Add update queue** - For very high concurrency, queue status updates
4. **Per-task status files** - Alternative architecture with per-task JSON files

## Artifact Types Summary

| Artifact | Location | Parallel Safety | Contention |
|----------|----------|-----------------|------------|
| status.json | plan-outputs/{plan}/status.json | Locked + Atomic | YES - shared |
| findings | plan-outputs/{plan}/findings/{task}.md | Isolated | NO |
| timestamps | plan-outputs/{plan}/timestamps/ | Multiple files | LOW |
| backup | plan-outputs/{plan}/status.json.bak | Single file | On recovery only |

## Integration with Batch Execution

**File Path:** `/home/benjamin/tools/dev_workflow/.claude/commands/plan/batch.md`

The batch command coordinates parallel task execution:

1. **Pre-execution:** Start run with `startRun(planPath)`
2. **Per-task start:** `markTaskStarted(planPath, taskId)` before launching agent
3. **Per-task complete:** `markTaskCompleted(planPath, taskId, findings)` immediately after
4. **Post-execution:** `completeRun(planPath, runId, completed, failed)`

Each status update uses the locking mechanism, ensuring safe concurrent access.

## Conclusions

### Strengths

1. **Atomic writes** prevent file corruption from crashes or interrupts
2. **File locking** with retries and jitter handles moderate concurrency
3. **Task-isolated findings** eliminate contention for output artifacts
4. **Read-only agent pattern** centralizes file writes in main conversation
5. **Safety net recalculation** catches and corrects any drift in summary counts
6. **Backup and recovery** mechanisms allow recovery from corruption

### Limitations

1. **Single status.json** is a contention point at high concurrency
2. **Lock timeout** (10s) may be insufficient for >5 parallel tasks
3. **No git coordination** for parallel task commits
4. **No queuing** for status updates under heavy load

### Recommendations

1. **Short-term:** Use batch operations where possible to reduce lock contention
2. **Medium-term:** Consider per-phase status files to distribute write load
3. **Long-term:** Implement status update queue for very high parallelism scenarios

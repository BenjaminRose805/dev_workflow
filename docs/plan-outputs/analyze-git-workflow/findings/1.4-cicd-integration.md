# Task 1.4: CI/CD Integration Analysis

## Overview

This analysis examines how the plan orchestration system should integrate with CI/CD systems and automated testing, considering PR workflows, testing triggers, pipeline integration, merge automation, and feedback loops.

## Current State

### Existing CI/CD References
- **No active CI/CD configuration**: No `.github/workflows`, `.gitlab-ci.yml`, or `Jenkinsfile` exists
- **Planned integrations**: Multiple implementation plans reference CI/CD:
  - `implement-review-command.md`: GitHub PR comments, status checks, Actions workflows
  - `implement-deploy-command.md`: Pre-flight validation, git status checks
  - `implement-release-command.md`: Tag creation, GPG signing, validation gates
  - `implement-test-command.md`: Test execution, coverage analysis
  - `implement-deploy-agent.md`: Blocking vs non-blocking checks, test validation

### Current Testing Capabilities
- **package.json**: Only placeholder test script (`echo "Error: no test specified" && exit 1`)
- **No test framework**: No Jest, Vitest, Mocha, or other testing infrastructure
- **Manual validation**: Plans include verification steps but no automated enforcement

## 1. PR Creation Strategy

### Timing Options

| Approach | Trigger | Pros | Cons | Recommendation |
|----------|---------|------|------|----------------|
| **Per-Plan** | After plan completion | Clean unit of work, clear scope | May be too large for review | **PRIMARY** |
| **Per-Phase** | After each phase completion | Incremental review, faster feedback | Many PRs, context switching | SECONDARY (for large plans) |
| **Manual** | User-initiated `/plan:pr` | Full control, flexibility | Easy to forget, inconsistent | FALLBACK |

### Recommended PR Creation Workflow

```bash
# After plan completion (all phases done)
# Triggered by: /plan:complete command

# 1. Validate state
git status --porcelain  # Must be clean
git diff main...HEAD    # Show changes

# 2. Create PR with auto-generated body
gh pr create \
  --title "Plan: {plan-name}" \
  --body "## Summary
{Auto-generated summary from plan phases}

## Tasks Completed
{Task completion summary by phase}

## Artifacts Generated
{List of findings/*.md files}

## Test Results
{If tests exist, include pass/fail status}

---
Generated by Plan Orchestration System" \
  --base main \
  --draft  # Start as draft by default
```

### Auto-Generated PR Description Components

**From Plan Context:**
1. **Summary section**: Extract from plan `## Overview` + phase summaries
2. **Task breakdown**: Group completed tasks by phase
3. **Artifacts**: Link to `docs/plan-outputs/{plan}/findings/*.md`
4. **Verification status**: Include VERIFY task results from status.json
5. **Metadata**: Duration, task count, failure count

**From Git State:**
1. **Changed files**: `git diff --name-status main...HEAD`
2. **Commit count**: Number of task commits in the plan branch
3. **Lines changed**: `git diff --stat main...HEAD`

### Draft vs Ready-for-Review

| State | Trigger | Use Case |
|-------|---------|----------|
| **Draft** | Default on PR creation | Plan complete but needs manual review before requesting reviewers |
| **Ready** | After user approval via `/plan:pr --ready` | All automated checks passed, ready for team review |
| **Auto-ready** | If all tests pass AND no blockers.md exists | Fully automated workflow for low-risk plans |

### Assignee/Reviewer Automation

**Auto-assignment strategies:**

1. **From plan metadata**: Add frontmatter to plans
   ```yaml
   ---
   plan: analyze-git-workflow
   assignee: @username
   reviewers: [@reviewer1, @reviewer2]
   ---
   ```

2. **From CODEOWNERS**: Use GitHub's CODEOWNERS for automatic assignment

3. **Round-robin**: Distribute reviews across team

### PR Templates and Labels

**Auto-labeling strategy:**

| Label | Condition |
|-------|-----------|
| `plan:analysis` | Plan name starts with `analyze-` |
| `plan:implementation` | Plan name starts with `implement-` |
| `plan:refactor` | Plan contains refactor tasks |
| `size:L/XL` | Based on lines changed (>500/1000) |
| `needs-tests` | No test files changed |
| `has-blockers` | blockers.md exists in findings |

## 2. Automated Testing Triggers

### Testing Strategy Matrix

| Trigger Point | Scope | Frequency | Blocking | Use Case |
|--------------|-------|-----------|----------|----------|
| **Per-commit** | Changed files only | Every task commit | Non-blocking | Fast feedback during development |
| **Per-phase** | Full test suite | Phase completion | Blocking | Gate before proceeding to next phase |
| **Per-plan** | Full + integration | Plan completion | Blocking | Gate before PR creation |
| **PR creation** | Full + E2E | On PR open | Blocking | Final validation before review |

### Recommended Testing Architecture

**Level 1: Fast per-task validation (Optional, non-blocking)**
```bash
# In /plan:implement after task completion
# Only if test framework detected

# Run tests for changed files only
CHANGED_FILES=$(git diff HEAD~1 --name-only)
npm test -- --findRelatedTests $CHANGED_FILES --bail

# Exit code 0: Continue
# Exit code 1: Warn but continue (mark task with warning)
```

**Level 2: Phase-level test gate (Recommended, blocking)**
```bash
# After all tasks in phase complete (in /plan:batch)
# Before marking phase complete in status.json

echo "Running phase verification tests..."
npm test -- --coverage

if [ $? -ne 0 ]; then
  echo "ERROR: Tests failed. Phase cannot complete."
  echo "Fix failing tests or use --skip-tests flag to override."
  exit 1
fi
```

**Level 3: Plan completion gate (Mandatory, blocking)**
```bash
# In /plan:complete before PR creation

# Full test suite
npm test -- --coverage --verbose

# Integration tests (if exist)
npm run test:integration

# E2E tests (if exist)
npm run test:e2e

# All must pass before PR creation
```

### Test Result Integration with Plan Status

**Extend status.json schema:**
```json
{
  "plan": "implement-feature-x",
  "status": "in_progress",
  "testing": {
    "last_run": "2025-12-24T10:30:00Z",
    "status": "passed|failed|skipped",
    "summary": {
      "total": 45,
      "passed": 43,
      "failed": 2,
      "skipped": 0
    },
    "failures": [
      {
        "test": "auth middleware validation",
        "file": "src/auth.test.js:23",
        "error": "Expected 401, got 403"
      }
    ],
    "coverage": {
      "lines": 85.2,
      "branches": 78.5,
      "functions": 90.1,
      "statements": 85.2
    }
  }
}
```

**Update commands:**
- `/plan:status` shows test summary
- `/plan:verify` runs tests and updates testing section
- `/plan:complete` blocks if `testing.status !== "passed"`

### Blocking vs Non-Blocking Failure Handling

**Non-blocking scenarios (warnings only):**
- Per-task tests during development
- Linter warnings
- Coverage decrease < 5%
- Non-critical checks

**Blocking scenarios (halt execution):**
- Phase completion tests
- Plan completion tests
- Security vulnerabilities
- Critical errors in VERIFY tasks

## 3. CI Pipeline Integration

### GitHub Actions Integration Pattern

**Workflow: `.github/workflows/plan-execution.yml`**

```yaml
name: Plan Execution CI

on:
  push:
    branches:
      - 'plan/**'      # All plan branches
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run tests
        run: npm test -- --coverage

      - name: Validate plan status
        run: node scripts/validate-plan-format.js

      - name: Check findings
        run: |
          if [ -f "docs/plan-outputs/*/findings/blockers.md" ]; then
            echo "::warning::Blockers detected in findings"
            cat docs/plan-outputs/*/findings/blockers.md
          fi

  plan-verification:
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    steps:
      - uses: actions/checkout@v4

      - name: Extract plan name from branch
        id: plan
        run: |
          PLAN_NAME=${GITHUB_REF#refs/heads/plan/}
          echo "name=$PLAN_NAME" >> $GITHUB_OUTPUT

      - name: Verify plan status
        run: |
          STATUS=$(jq -r '.status' docs/plan-outputs/${{ steps.plan.outputs.name }}/status.json)
          if [ "$STATUS" = "failed" ]; then
            echo "::error::Plan has failed tasks"
            exit 1
          fi

      - name: Generate plan summary
        run: |
          node scripts/status-cli.js summary ${{ steps.plan.outputs.name }} > $GITHUB_STEP_SUMMARY
```

### Branch Protection Configuration

**Required for `main` branch:**

**Settings:**
- Require status checks to pass before merging
  - `test` (GitHub Actions job)
  - `plan-verification` (GitHub Actions job)
- Require branches to be up to date before merging
- Require pull request reviews (1 approval)
- Dismiss stale reviews when new commits are pushed

### Status Checks and Required Checks

**Status check hierarchy:**

1. **Required (blocking merge):**
   - `test` - All tests pass
   - `plan-verification` - Plan status.json shows no failed tasks
   - `coverage` - Coverage meets threshold (e.g., >80%)

2. **Optional (informational):**
   - `lint` - Code style issues
   - `security-scan` - Dependency vulnerabilities
   - `performance` - Performance regression checks

### Artifact Generation and Preservation

**GitHub Actions artifact upload:**
```yaml
- name: Upload plan artifacts
  uses: actions/upload-artifact@v3
  with:
    name: plan-outputs-${{ steps.plan.outputs.name }}
    path: |
      docs/plan-outputs/${{ steps.plan.outputs.name }}/findings/
      docs/plan-outputs/${{ steps.plan.outputs.name }}/status.json
    retention-days: 30

- name: Upload test results
  uses: actions/upload-artifact@v3
  if: always()
  with:
    name: test-results
    path: |
      coverage/
      test-results/
```

**Artifact consumption:**
- Download in review jobs
- Attach to PR comments
- Compare across runs for regression detection

## 4. Merge Automation

### Auto-Merge Strategy

**Safety conditions (all must be true):**
1. All required status checks passed
2. Required approvals received (if configured)
3. No merge conflicts
4. No `blockers.md` in findings/
5. PR labeled with `auto-merge`
6. Plan status.json shows `status: "completed"`

### Merge Queue Integration

**GitHub merge queue configuration:**
```json
{
  "merge_queue": {
    "enabled": true,
    "merge_method": "squash",
    "queue_merge_method": "auto",
    "minimum_approvals": 1,
    "merge_commit_message": "title_and_body"
  }
}
```

**Orchestrator integration:**
```bash
# After PR creation in /plan:complete
if [ "$AUTO_MERGE" = "true" ]; then
  gh pr merge --auto --squash $PR_NUMBER
  echo "PR added to merge queue"
fi
```

### Branch Protection Compatibility

**Orchestrator must respect:**
- Required status checks (don't bypass)
- Required reviews (wait for approvals)
- Signed commits (configure git to sign)
- Linear history (use squash or rebase)

### Required Approvals Handling

**Auto-request reviews on PR creation:**
```bash
# In /plan:complete
REVIEWERS=$(extract_reviewers_from_plan)
gh pr create \
  --reviewer "$REVIEWERS" \
  --assign @me

# Send notification
echo "PR created. Requested reviews from: $REVIEWERS"
```

## 5. Feedback Loops

### CI Status Back to Orchestrator

**Poll-based approach (no webhook):**
```bash
# In /plan:status command
# Check CI status via gh CLI

if [ -n "$GITHUB_REPOSITORY" ]; then
  CI_STATUS=$(gh run list --branch plan/$PLAN_NAME --limit 1 --json conclusion -q '.[0].conclusion')
  echo "Latest CI status: $CI_STATUS"
fi
```

### Failed Test Analysis

**Automatic failure analysis:**

```markdown
# Test Failure Analysis

## Summary
5 tests failed in phase 2 verification

## Failed Tests

### 1. Auth middleware validation
- **File:** `src/auth.test.js:23`
- **Error:** `Expected 401, got 403`
- **Likely cause:** Incorrect error code in middleware
- **Suggested fix:** Update `src/auth.js:45` to return 401 for unauthenticated requests
- **Related task:** Task 2.3 (Implement auth middleware)

## Recommended Actions
1. Fix auth middleware error code (Quick fix)
2. Review database connection configuration (Needs investigation)
3. Re-run tests with `npm test -- --coverage`
```

### Retry Mechanisms

**Automatic retry strategies:**

| Failure Type | Retry Strategy | Max Retries | Backoff |
|-------------|----------------|-------------|---------|
| **Flaky test** | Immediate retry | 3 | None |
| **Network error** | Exponential backoff | 5 | 2^n seconds |
| **Resource timeout** | Linear backoff | 3 | 10s |
| **Build failure** | No retry | 0 | N/A |

### Notification Systems

**Multi-channel notification strategy:**

| Event | Terminal | Status.json | Webhook | Email | When |
|-------|----------|-------------|---------|-------|------|
| Task complete | Yes | Yes | No | No | Every task |
| Phase complete | Yes | Yes | Yes | No | Every phase |
| Plan complete | Yes | Yes | Yes | Yes | Plan done |
| Test failure | Yes | Yes | Yes | No | Blocking failures |
| CI failure | Yes | Yes | Yes | Yes | Critical failures |
| PR created | Yes | Yes | Yes | Yes | PR events |

**Webhook notification payload:**
```json
{
  "event": "plan.completed",
  "timestamp": "2025-12-24T10:30:00Z",
  "plan": {
    "name": "implement-feature-x",
    "status": "completed",
    "duration": "45m 23s",
    "tasks": {
      "total": 12,
      "completed": 12,
      "failed": 0
    }
  },
  "ci": {
    "status": "passed",
    "run_url": "https://github.com/.../actions/runs/123"
  },
  "pr": {
    "number": 456,
    "url": "https://github.com/.../pull/456"
  }
}
```

## Summary & Recommendations

### Recommended CI/CD Integration Architecture

**Phase 1: Foundation (Immediate)**
1. **PR creation on plan completion** - Auto-generate PRs with plan context
2. **Basic GitHub Actions workflow** - Run tests on plan branches
3. **Status checks** - Block merges on test failures
4. **Draft PRs by default** - Manual approval before requesting reviews

**Phase 2: Automation (Near-term)**
5. **Test execution in phases** - Run tests after each phase completion
6. **Test result tracking** - Extend status.json with test data
7. **Auto-labeling** - Label PRs based on plan type and size
8. **Branch protection** - Enforce status checks and reviews

**Phase 3: Advanced (Long-term)**
9. **Auto-merge on success** - Merge PRs when all checks pass
10. **Merge queue integration** - Use GitHub merge queue
11. **CI feedback loop** - Webhook integration for CI status
12. **Multi-channel notifications** - Slack, email, terminal, status.json

### Key Design Decisions

| Decision | Recommendation | Rationale |
|----------|----------------|-----------|
| **PR timing** | Per-plan (default), per-phase (optional) | Clean unit of work, reduces PR noise |
| **PR state** | Draft by default | Prevents premature reviews, allows manual verification |
| **Test triggers** | Per-phase (blocking), per-plan (blocking) | Balance speed and safety |
| **Test scope** | Changed files (per-task), full suite (per-phase) | Fast feedback without compromising quality |
| **Merge strategy** | Squash merge | Clean history, easy rollback |
| **Auto-merge** | Opt-in via label | Safety first, automation for low-risk plans |
| **CI platform** | GitHub Actions (primary), extensible | Most common, good GitHub integration |
| **Notifications** | Terminal + status.json (always), webhooks (opt-in) | Progressive enhancement |

### Risk Mitigation

| Risk | Mitigation |
|------|------------|
| **Over-automation** | Start with draft PRs, require manual approval |
| **Test flakiness** | Implement retry logic, track flaky tests |
| **CI failures blocking work** | Allow `--skip-ci` flag for emergencies |
| **Large PRs** | Support per-phase PRs for large plans |
| **Merge conflicts** | Require branches up to date, use merge queue |
| **Missing tests** | Block plan completion if no tests exist (optional) |

### Next Steps

1. **Design `/plan:complete` command** - Implement PR creation workflow
2. **Create GitHub Actions templates** - Provide starter workflows
3. **Extend status.json schema** - Add CI and test result fields
4. **Implement test execution in /plan:verify** - Integrate test running
5. **Document CI/CD patterns** - Create setup guides and best practices
